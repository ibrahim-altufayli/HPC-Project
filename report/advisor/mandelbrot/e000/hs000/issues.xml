<?xml version='1.0' encoding='UTF-8'?>

<bag xmlns:float="http://www.w3.org/2001/XMLSchema#float" xmlns:int="http://www.w3.org/2001/XMLSchema#int" xmlns:unsignedInt="http://www.w3.org/2001/XMLSchema#unsignedInt" xmlns:unsignedLong="http://www.w3.org/2001/XMLSchema#unsignedLong" int:version="16">
 <issues>
  <issue>
   <unsignedInt:flags>66</unsignedInt:flags>
   <id>compiler_diag_issue_15520</id>
   <int:severity>1</int:severity>
   <text>compiler_diag_issue_15520_text</text>
   <title>compiler_diag_issue_15520_title</title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>compiler_diag_rec_15520</id>
     <text>compiler_diag_rec_15520_text_c</text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>3</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_type_conversions</id>
   <int:severity>1</int:severity>
   <text>There are multiple data types within loops. Utilize hardware vectorization support more effectively by avoiding data type conversion. </text>
   <title>Data type conversions present </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_type_conversions_smallest_c</id>
     <text>The &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;source loop&lt;/a&gt; contains data types of different widths. To fix: Use the smallest data type that gives the needed precision to use the entire &lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;vector register width&lt;/a&gt;.
&lt;/br&gt;&lt;b&gt;Example:&lt;/b&gt; If only 16-bits are needed, using a short rather than an int can make the difference between eight-way or four-way SIMD parallelism, respectively. </text>
     <title>Use the smallest data type </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>66</unsignedInt:flags>
   <id>compiler_diag_issue_15541</id>
   <int:severity>1</int:severity>
   <text>&lt;b&gt;Cause:&lt;/b&gt; The compiler vectorizer determined outer loop vectorization is not possible using auto-vectorization. &lt;br/&gt; &lt;b&gt;C++ Example:&lt;/b&gt;
&lt;div class=&quot;sample&quot;&gt;&lt;br/&gt;void foo(float **a, float **b, int N){&lt;br/&gt;
&amp;nbsp;&amp;nbsp;int i, j;&lt;br/&gt;
&lt;b&gt;#pragma ivdep&lt;br/&gt;
&amp;nbsp;&amp;nbsp;for (i=0; i &amp;lt; N; i++){ &lt;/b&gt; &lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;float *ap = a[i];&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;float *bp = b[i];&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;for (j=0; j &amp;lt; N; j++){&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;ap[j] = bp[j];&lt;br/&gt;
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
&amp;nbsp;&amp;nbsp;}&lt;br/&gt;
} &lt;/div&gt;  </text>
   <title>Outer loop was not auto-vectorized </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>compiler_diag_rec_15541</id>
     <text>&lt;ul&gt; &lt;li&gt;Run a Dependencies analysis to check if the loop has real dependencies. There are two types of dependencies: &lt;ul&gt; &lt;li&gt;True dependency - Read after write (RAW) &lt;/li&gt; &lt;li&gt;Anti-dependency - Write after read (WAR) &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;If no dependencies exist, use one of the following to tell the compiler it is safe to vectorize: &lt;ul&gt; &lt;li&gt;Directive to prevent all dependencies in the loop &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Source Loop &lt;/td&gt; &lt;td&gt;#pragma simd or #pragma omp simd &lt;/td&gt; &lt;td&gt;!DIR$ SIMD or !$OMP SIMD &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/li&gt; &lt;li&gt;Directive to ignore only vector dependencies (which is safer) &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Source Loop &lt;/td&gt; &lt;td&gt;#pragma ivdep&lt;/td&gt; &lt;td&gt;!DIR$ IVDEP &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/li&gt; &lt;li&gt;&lt;div class=&quot;inplace_sample&quot;&gt;restrict&lt;/div&gt; keyword &lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;If anti-dependency exists, use a directive where &lt;div class=&quot;inplace_sample&quot;&gt;k&lt;/div&gt; is smaller than the distance between dependent items in anti-dependency. This enables vectorization, as dependent items are put into different vectors: &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Source Loop &lt;/td&gt; &lt;td&gt;#pragma simd vectorlength(k)&lt;/td&gt; &lt;td&gt;!DIR$ SIMD VECTORLENGTH(k) &lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/li&gt; &lt;li&gt;If using the &lt;div class=&quot;inplace_sample&quot;&gt;O3&lt;/div&gt; compiler option, use a directive before the inner and outer loops to request vectorization of the outer loop: &lt;table&gt; &lt;tr&gt; &lt;th&gt;Target &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;ICL/ICC/ICPC&lt;/a&gt; Directive &lt;/th&gt; &lt;th&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/intel-advisor-xe-2016-vectorization-advisor-glossary&quot;&gt;IFORT&lt;/a&gt; Directive &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Inner loop &lt;/td&gt; &lt;td&gt;#pragma novector&lt;/td&gt; &lt;td&gt;!DIR$ NOVECTOR&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Outer loop&lt;/td&gt; &lt;td&gt;#pragma vector always&lt;/td&gt; &lt;td&gt;!DIR$ VECTOR ALWAYS&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;/li&gt; &lt;/ul&gt; &lt;b&gt;Read More C++ Information:&lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/cdiag15541&quot;&gt;https://software.intel.com/en-us/articles/cdiag15541&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-B25ABCC2-BE6F-4599-AEDF-2434F4676E1B.html&quot;&gt;ivdep&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-CFBEC461-748D-4162-A669-C4F42848267F.html&quot;&gt;novector&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-CDCCCACD-A61C-40C5-A342-E452C95E1608.html&quot;&gt;O&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-4D8CDB9C-8A96-4CB2-B5E5-3D81003FE4FF.html&quot;&gt;omp simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-1EA04294-988E-4152-B584-B028FD6FAC48.html&quot;&gt;simd&lt;/a&gt;, &lt;a href=&quot;C++/17/index.htm#GUID-2B528C72-29B4-4DBC-8B91-EE4D1A03A850.html&quot;&gt;vector&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/articles/getting-started-with-intel-composer-xe-2013-compiler-pragmas-and-directives&quot;&gt;Getting Started with Intel Compiler Pragmas and Directives&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;  </text>
     <title>Recommendations </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>6</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_fma</id>
   <int:severity>1</int:severity>
   <text>Your current hardware supports the AVX2 instruction set architecture (ISA), which enables the use of fused multiply-add (FMA) instructions. Improve performance by utilizing FMA instructions. </text>
   <title>Potential underutilization of FMA instructions </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_fma_target_avx2_isa_c</id>
     <text>Although static analysis presumes the loop may benefit from FMA instructions available with the AVX2 ISA, no AVX2-specific code executed for this loop. To fix: Use the &lt;div class=&quot;inplace_sample&quot;&gt;xCORE-AVX2&lt;/div&gt; compiler option to generate AVX2-specific code, or the &lt;div class=&quot;inplace_sample&quot;&gt;axCORE-AVX2&lt;/div&gt; compiler option to enable multiple, feature-specific, auto-dispatch code generation, including AVX2. &lt;table&gt; &lt;tr&gt; &lt;th&gt; Windows* OS &lt;/th&gt; &lt;th&gt; Linux* OS &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/QxCORE-AVX2 or /QaxCORE-AVX2&lt;/td&gt; &lt;td&gt;-xCORE-AVX2 or -axCORE-AVX2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More: &lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-2D881A91-C5D7-4DDD-84B1-FB9D0D597F4D.htm&quot;&gt;ax, Qax&lt;/a&gt;; &lt;a href=&quot;C++/17/index.htm#GUID-09734487-1819-4C1E-B314-2497F2B64C45.htm&quot;&gt;x, Qx&lt;/a&gt;
&lt;li&gt;&lt;em&gt;Code Generation Options&lt;/em&gt; in the &lt;a href=&quot;https://software.intel.com/en-us/intel-cplusplus-compiler-16.0-user-and-reference-guide&quot;&gt;Intel&amp;reg; C++ Compiler 16.0 User and Reference Guide&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/blogs/2016/01/13/compiling-for-the-intel-xeon-phi-processor-x200-and-the-intel-avx-512-isa&quot;&gt;Compiling for the Intel&amp;reg; Xeon Phi&amp;trade; processor x200 and the Intel&amp;reg; AVX-512 ISA&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Target the AVX2 ISA </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>7</unsignedLong:rowKey>
  </issue>
  <issue>
   <unsignedInt:flags>65</unsignedInt:flags>
   <id>issue_fma</id>
   <int:severity>1</int:severity>
   <text>Your current hardware supports the AVX2 instruction set architecture (ISA), which enables the use of fused multiply-add (FMA) instructions. Improve performance by utilizing FMA instructions. </text>
   <title>Potential underutilization of FMA instructions </title>
   <attributes>
    <float:severity>1</float:severity>
   </attributes>
   <parameters/>
   <recommendations>
    <recommendation>
     <int:confidence>1</int:confidence>
     <unsignedInt:flags>8</unsignedInt:flags>
     <id>rec_fma_target_avx2_isa_c</id>
     <text>Although static analysis presumes the loop may benefit from FMA instructions available with the AVX2 ISA, no AVX2-specific code executed for this loop. To fix: Use the &lt;div class=&quot;inplace_sample&quot;&gt;xCORE-AVX2&lt;/div&gt; compiler option to generate AVX2-specific code, or the &lt;div class=&quot;inplace_sample&quot;&gt;axCORE-AVX2&lt;/div&gt; compiler option to enable multiple, feature-specific, auto-dispatch code generation, including AVX2. &lt;table&gt; &lt;tr&gt; &lt;th&gt; Windows* OS &lt;/th&gt; &lt;th&gt; Linux* OS &lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;/QxCORE-AVX2 or /QaxCORE-AVX2&lt;/td&gt; &lt;td&gt;-xCORE-AVX2 or -axCORE-AVX2&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt; &lt;b&gt;Read More: &lt;/b&gt; &lt;ul&gt; &lt;li&gt;&lt;a href=&quot;C++/17/index.htm#GUID-2D881A91-C5D7-4DDD-84B1-FB9D0D597F4D.htm&quot;&gt;ax, Qax&lt;/a&gt;; &lt;a href=&quot;C++/17/index.htm#GUID-09734487-1819-4C1E-B314-2497F2B64C45.htm&quot;&gt;x, Qx&lt;/a&gt;
&lt;li&gt;&lt;em&gt;Code Generation Options&lt;/em&gt; in the &lt;a href=&quot;https://software.intel.com/en-us/intel-cplusplus-compiler-16.0-user-and-reference-guide&quot;&gt;Intel&amp;reg; C++ Compiler 16.0 User and Reference Guide&lt;/a&gt; &lt;li&gt;&lt;a href=&quot;https://software.intel.com/en-us/blogs/2016/01/13/compiling-for-the-intel-xeon-phi-processor-x200-and-the-intel-avx-512-isa&quot;&gt;Compiling for the Intel&amp;reg; Xeon Phi&amp;trade; processor x200 and the Intel&amp;reg; AVX-512 ISA&lt;/a&gt; and &lt;a href=&quot;https://software.intel.com/en-us/vectorization-resources-advisor&quot;&gt;Vectorization Resources for Intel&amp;reg; Advisor Users&lt;/a&gt; &lt;/ul&gt; </text>
     <title>Target the AVX2 ISA </title>
     <attributes>
      <float:confidence>1</float:confidence>
     </attributes>
     <parameters/>
    </recommendation>
   </recommendations>
   <unsignedLong:rowKey>12</unsignedLong:rowKey>
  </issue>
 </issues>
 <traits>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>13</int:id>
   <text>System Function Calls Present </text>
   <unsignedLong:rowKey>1</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>0</int:fieldId>
   <int:id>14</int:id>
   <text>Indirect Function Calls Present </text>
   <unsignedLong:rowKey>1</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>155</int:fieldId>
   <int:id>4</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>3</unsignedLong:rowKey>
  </trait>
  <trait>
   <int:fieldId>148</int:fieldId>
   <int:id>5</int:id>
   <text>Low Trip Counts May Produce Ineffective Peeled/Remainder Loops After Vectorization - Consider Adding Data Padding or Identifying Expected Number of Iterations </text>
   <unsignedLong:rowKey>3</unsignedLong:rowKey>
  </trait>
 </traits>
</bag>
